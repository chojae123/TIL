## 좋은 feature란 무엇인가?
- 구하려는 값과 관계가 있는 특성    
데이터 세트에서 최소 5번 이상 등장하여 label과의 관계를 학습할 수 있도록 만들어주는 특성
- 충분한 example수가 있는 특성  
특성이 적게 분포한다면 학습이 어렵다.
- 가급적 분명하고 명확한 의미 부여   
명확하고 분명한 의미를 갖고 있어, 구성원 모두가 파악할 수 있는 특성

## 상관관계와 인과관계
변수가 변할 때 다른 변수도 변한다면 두 변수 사이엔 상관관계가 있다고 볼 수 있다.     
그러나 상관관계에서의 두 변수 사이엔 인과적 선후관계가 없다.   
반면에 인과관계는 두 변수 간에 인과성이 있다. 즉 원인과 결과가 있는 것이다.   

## Cross Validation은 무엇이고 어떻게 해야하나요?
데이터 셋을 학습시킬 때 우리는 train set과 validation set을 나눠 train set으로 학습시킨 model을 validation set을 통해 검증한다.  
이때, 모델의 성능을 올리기 위해 파라미터 수정등의 과정을 거치는데   
하나의 validation set을 활용할 경우, 그 validation set에 모델이 과적합되는 경우가 생긴다.
이를 막기위해 데이터셋을 여러개로 쪼개 그 쪼갠 모든 부분을 활용하여 검증을 하여 모델의 과적합을 방지할 수 있다.

## 회귀문제에서 사용할 수 있는 metric
크기 의존적 오차 
- MAE (오차의 절댓값의 평균)
- RMSE (오차의 제곱의 평균에 제곱근을 씌운 형태)
-> rmse는 오차가 커질수록 그 페널티가 커지는 형식.

비율 의존적 오차    
- MAPE(오차/실제값의 평균을 낸뒤 100을 곱해 백분율로 표시)

## 분류문제에서 사용할 수 있는 metric
- Accuracy (모델의 정확도)      
전체 데이터에서 실제 true와 실제 false를 예측한 것의 비율
- recall (재현율)   
실제 True인 것 중에서 모델이 True라고 예측한 것의 비율입니다. 
- precision (정밀도)   
모델이 True라고 분류한 것 중에서 실제 True인 것의 비율입니다.

## 정규화를 해야하는 이유
데이터가 가진 feature의 스케일이 심하게 차이가 나는 경우 문제가 되기 때문이다.   
모델이 받아들이는 데이터의 크기가 들쑥날쑥하다면 모델이 데이터를 이상하게 해석할 우려가 있다.

## 정규화의 종류
 - Min-Max Normalization (최소-최대 정규화)  
모든 feature에 대해 각각의 최소값을 0, 최대값을 1로, 그리고 다른 값들은 0과 1 사이의 값으로 변환
(X - X.min)/ (X.max - X.min)

 -Z-Score Normalization (Z-점수 정규화)   
 (X - 평균) / 표준편차   
 만약 feature의 값이 평균과 일치하면 0으로 정규화되겠지만, 평균보다 작으면 음수, 평균보다 크면 양수로 나타난다.    
 이 때 계산되는 음수와 양수의 크기는 그 feature의 표준편차에 의해 결정된다.    
만약 데이터의 값이 넓게 퍼져있으면 정규화되는 값이 0에 가까워진다.
 
